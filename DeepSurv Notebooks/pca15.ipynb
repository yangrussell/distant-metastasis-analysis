{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoreloads modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import libraries\n",
    "import sys\n",
    "import statistics\n",
    "import random\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to the correct directory\n",
    "sys.path.append('../deepsurv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changed from deep_surv to deepsurv\n",
    "import deepsurv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import loggers, visualization libraries, and other libraries\n",
    "from deepsurv_logger import DeepSurvLogger, TensorboardLogger\n",
    "import utils\n",
    "import viz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lasagne\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import pylab \n",
    "import scipy.stats as stats\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The file paths to the bootstrapping PCA component set\n",
    "model_data_fp = 'C:/Users/russe/Downloads/PRECOG_DMFS/Significant/Breast cancer.GSE3494.HGU133A_EntrezCDF.model.pca.tsv'\n",
    "\n",
    "# The file paths to the 70% clinical annotation datasets\n",
    "model_info_fp = 'C:/Users/russe/Downloads/PRECOG_DMFS/Split/Breast cancer.GSE3494.HGU133A_EntrezCDF.DMFS.test.info.tsv'\n",
    "\n",
    "# Use pandas to read all datasets\n",
    "model_data_df = pd.read_csv(model_data_fp, sep = \"\\t\")\n",
    "model_info_df = pd.read_csv(model_info_fp, sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the gene expression dataset to contain the desired number of PCs (15)\n",
    "model_data_df = model_data_df.iloc[:,0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the indices to be numbers in the test gene expression dataset\n",
    "model_data_df = model_data_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform the dataset to \"DeepSurv\" format\n",
    "DeepSurv expects a dataset to be in the form:\n",
    "\n",
    "    {\n",
    "        'x': numpy array of float32\n",
    "        'e': numpy array of int32\n",
    "        't': numpy array of float32\n",
    "        'hr': (optional) numpy array of float32\n",
    "    }\n",
    "    \n",
    "You are providing me a csv, which I read in as a pandas dataframe. Then I convert the pandas dataframe into the DeepSurv dataset format above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function converts the data into the format required by DeepSurv. I have modified\n",
    "this function from the original DeepSurv function.\n",
    "event_col is the header in the df that represents the 'Event / Status' indicator\n",
    "time_col is the header in the df that represents the event time\n",
    "\n",
    "Parameters:\n",
    "df - the info (clinical annotation) dataframe\n",
    "gene - the data (gene expression) dataframe\n",
    "event_col - the column containing the event; defaults to DMFS_Status\n",
    "time_col - the column containing the time; defaults to DMFS_Time\n",
    "\"\"\"\n",
    "def dataframe_to_deepsurv_ds(df, gene, event_col = 'DMFS_Status', time_col = 'DMFS_Time'):\n",
    "    # Extract the event and time columns as numpy arrays\n",
    "    e = df[event_col].values.astype(np.int32)\n",
    "    t = df[time_col].values.astype(np.float32)\n",
    "    \n",
    "    # Use the gene expression\n",
    "    x = gene.values.astype(np.float32)\n",
    "    \n",
    "    # Return the deep surv dataframe\n",
    "    return {\n",
    "        'x' : x,\n",
    "        'e' : e,\n",
    "        't' : t\n",
    "    }\n",
    "\n",
    "# If the headers of the csv change, you can replace the values of \n",
    "# 'event_col' and 'time_col' with the names of the new headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists to store the various train and out-of-bag concordance indices\n",
    "train_list = []\n",
    "oob_list = []\n",
    "\n",
    "# The bootstrapping process is repeated 100 times\n",
    "for i in range(100):\n",
    "    # Generate a random number for n to be used as a random seed. The same seed (n) will be usedfor resampling the clinical\n",
    "    # annotation and gene expression datasets\n",
    "    n = random.randrange(0, 1000)\n",
    "    \n",
    "    # Resampling the datasets with the same random seed\n",
    "    train_info_df = resample(model_info_df, replace=True, n_samples=176, random_state=n)\n",
    "    train_data_df = resample(model_data_df, replace=True, n_samples=176, random_state=n)\n",
    "\n",
    "    # Get a list of the rows that have been selected in the bootstrapping process\n",
    "    used_rows = list(train_info_df.index.values)\n",
    "\n",
    "    # Take the set difference between all the rows and the used ones. Subset the info and data files according\n",
    "    # to these selected rows\n",
    "    oob_info_df = model_info_df.loc[set(model_info_df.index.values) - set(used_rows)]\n",
    "    oob_data_df = model_data_df.loc[set(model_data_df.index.values) - set(used_rows)]\n",
    "    \n",
    "    # Convert the data to the correct format for DeepSurv\n",
    "    train_data = dataframe_to_deepsurv_ds(train_info_df, train_data_df, event_col = 'DMFS_Status', time_col = 'DMFS_Time')\n",
    "    oob_data = dataframe_to_deepsurv_ds(oob_info_df, oob_data_df, event_col = 'DMFS_Status', time_col = 'DMFS_Time') \n",
    "    \n",
    "    # Manually chosen hyperparameters\n",
    "    hyperparams = {\n",
    "        'L2_reg': 10.0,\n",
    "        'batch_norm': True,\n",
    "        'dropout': 0.4,\n",
    "        'hidden_layers_sizes': [25, 25],\n",
    "        'learning_rate': 1e-05,\n",
    "        'lr_decay': 0.001,\n",
    "        'momentum': 0.9,\n",
    "        'n_in': train_data['x'].shape[1],\n",
    "        'standardize': True\n",
    "    }\n",
    "    # Create an instance of DeepSurv using the hyperparams defined above\n",
    "    model = deepsurv.DeepSurv(**hyperparams)\n",
    "    # changed the above thing from deep_surv to deepsurv\n",
    "\n",
    "    # DeepSurv can now leverage TensorBoard to monitor training and validation\n",
    "    # This section of code is optional. If you don't want to use the tensorboard logger\n",
    "    # Uncomment the below line, and comment out the other three lines: \n",
    "    #logger = None\n",
    "\n",
    "    experiment_name = 'test_experiment_sebastian'\n",
    "    logdir = './logs/tensorboard/'\n",
    "    logger = TensorboardLogger(experiment_name, logdir=logdir)\n",
    "\n",
    "    # Now we train the model\n",
    "    update_fn=lasagne.updates.nesterov_momentum # The type of optimizer to use. \\\n",
    "                                                # Check out http://lasagne.readthedocs.io/en/latest/modules/updates.html \\\n",
    "                                                # for other optimizers to use\n",
    "    n_epochs = 2000\n",
    "    metrics = model.train(train_data, n_epochs=n_epochs, logger=logger, update_fn=update_fn)\n",
    "    # Print the final metrics\n",
    "    train_index = metrics['c-index'][-1]\n",
    "    print('Train C-Index:', train_index)\n",
    "    train_list.append(train_index)\n",
    "    # print('Valid C-Index: ',metrics['valid_c-index'][-1])\n",
    "\n",
    "    # Plot the training / validation curves\n",
    "    viz.plot_log(metrics)\n",
    "    test_index = model.get_concordance_index(**oob_data)\n",
    "    print(hyperparams)\n",
    "    print('Test C-Index:', test_index)\n",
    "    oob_list.append(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a list comprehension to extract concordance indices from the train list\n",
    "new_train_list = [x[1] for x in train_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mean train concordance index\n",
    "statistics.mean(new_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mean out-of-bag concordance index\n",
    "statistics.mean(oob_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a formatted plot of the histogram of oob concordance indices\n",
    "# I tried to match the style to what R outputs as a histogram (as closely as possible)\n",
    "plt.rcParams.update({'font.size': 30}) # Set font size\n",
    "plt.figure(figsize=(15,10), dpi = 300) # Set figure size & resolution\n",
    "plt.xlabel(\"x\",labelpad=20)            # Set x-label padding\n",
    "plt.ylabel(\"y\",labelpad=20)            # Set y-label padding\n",
    "plt.ylabel(\"Frequency\")                # Set x-label\n",
    "plt.xlabel(\"OOB concordance index\")    # Set y-label\n",
    "num_bins = 8                           # Choose the number of histogram bins\n",
    "plt.xticks([0.4, 0.5, 0.6, 0.7])       # Set tick marks\n",
    "\n",
    "# Create the histogram\n",
    "n, bins, patches = plt.hist(oob_list, num_bins, facecolor = 'green', edgecolor = 'black', alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 30}) # Set the font size\n",
    "plt.figure(figsize=(15,10), dpi = 300) # Set the figure size & resolution\n",
    "plt.xlabel(\"x\",labelpad=20)            # Set the x-label padding\n",
    "plt.ylabel(\"y\",labelpad=20)            # Set the y-label padding\n",
    "plt.title(\"\", y=1.08)                  # Make the titel higher above the plot\n",
    "\n",
    "\n",
    "# Create the quantile-quantiles plot against a normal distribution\n",
    "stats.probplot(oob_list, dist=\"norm\", plot=pylab)\n",
    "pylab.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
